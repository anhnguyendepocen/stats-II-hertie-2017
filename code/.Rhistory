summary(wage_model <- lm(wage ~ exper*tenure -tenure, data = wage1))
data("wage1")
table(wage1$edu)
# recode continuous variable to discrete variable
table(wage1$edu)
wage1$educ_cat <- car::recode(wage1$educ, "0:9='low' ;
10:14='medium' ;
15:18='high'",
as.factor.result = TRUE,
levels = c("low", "medium", "high"))
table(wage1$educ_cat)
summary(wage_model <- lm(wage ~ educ_cat*female, data = wage1))
summary(wage_model <- lm(wage ~ educ_cat, data = wage1))
summary(wage_model <- lm(wage ~ educ_cat*female, data = wage1))
library(interplot)
summary(wage_model <- lm(wage ~ exper*tenure, data = wage1))
interplot(m = wage_model, var1 = "exper", var2 = "tenure", hist  = TRUE) +
xlab('Tenure') +
ylab('Estimated coefficient for experience') +
ggtitle('Estimated coefficient of experience\non wage by tenure') +
theme(plot.title = element_text(face='bold'))
# continuous * discrete setup
wage1$woman <- as.factor(wage1$female)
summary(wage_model <- lm(wage ~ exper*woman, data = wage1))
# tenure as mediator
interplot(m = wage_model, var1 = "exper", var2 = "woman") +
xlab('Woman') +
ylab('Estimated coefficient for experience') +
ggtitle('Estimated coefficient of experience\non wage by gender') +
theme(plot.title = element_text(face='bold'))
35.7+22.4+9.5+7.8+9.3+10.8
source("packages.r")
load("/Users/simonmunzert/rkeys.RDa")
MashapeKey <- "4iRXckVxudmshmuVeHLKPAUUMCu6p1cp4iUjsnQO3ipKkD4GSj"
botometerURL <- "https://osome-botometer.p.mashape.com/2/check_account"
Tweetson <- function(x) {
user <- lookup_users(x, token = twitter_token, parse = FALSE)
timeline <- get_timeline(x, token = twitter_token, parse = FALSE, n = 200)
mentions <- search_tweets(x, token = twitter_token, parse = FALSE, n = 100)
payload <- list(timeline = timeline, mentions = mentions, user = user)
payload.json <- toJSON(payload, null = "null", na = "null", pretty = TRUE)
print(payload.json)
write(payload.json, "testload.json")
}
Tweetson("TimK16141864")
library(jsonlite)
library(httr)
library(magrittr)
library(rtweet)
Tweetson("TimK16141864")
load("/Users/simonmunzert/rkeys.RDa")
twitter_token <- TwitterToR_twitterkey
Tweetson("TimK16141864")
twitter_token <- TwitterToR_twittersecret
Tweetson("TimK16141864")
key <- TwitterToR_twitterkey
## api secret (example below is not a real key)
secret <- TwitterToR_twittersecret
twitter_token <- create_token(
app = appname,
consumer_key = key,
consumer_secret = secret)
load("/Users/simonmunzert/rkeys.RDa")
appname <- "TwitterToR"
## api secret (example below is not a real key)
secret <- TwitterToR_twittersecret
twitter_token <- create_token(
app = appname,
consumer_key = key,
consumer_secret = secret)
Tweetson("TimK16141864")
source("packages.r")
data(traffic2)
?traffic2
traffic2_ts <- ts(traffic2, frequency = 12, start = 1981)
traffic2_xts <- as.xts(traffic2_ts)
plot(traffic2_xts$totacc)
plot(traffic2_xts$totacc)
?addEventLines
View(traffic2_xts)
plot(traffic2_xts$totacc)
plot(traffic2_xts$totacc)
View(traffic2_xts)
View(traffic2)
traffic2_ts <- ts(traffic2, frequency = 12, start = 1981)
View(traffic2_ts)
class(traffic2_ts)
traffic2_ts$year
traffic2_ts[,"year"]
traffic2_xts[as.logical(diff(traffic2_xts$beltlaw)),]
invisible(plot(traffic2_xts$totacc))
invisible(addEventLines(traffic2_xts[as.logical(diff(traffic2_xts$beltlaw)),], lwd = 2, col = "red"))
addEventLines(traffic2_xts[as.logical(diff(traffic2_xts$spdlaw)),], lwd = 2, col = "red", srt = 90)
diff(traffic2_xts$spdlaw)
traffic2_xts$totacc
?traffic2
summary(lm(totacc ~ t + feb + mar + apr + may + jun + jul + aug + sep + oct + nov + dec, data = traffic2_xts))
View(traffic2)
plot(stl(traffic2_xts$fatacc, s.window = "periodic"))
plot(stl(traffic2_xts$fatacc, s.window = "periodic"))
plot(stl(traffic2_xts$injacc, s.window = "periodic"))
summary(lm(totacc ~ year + feb + mar + apr + may + jun + jul + aug + sep + oct + nov + dec +
summary(lm(totacc ~ year + feb + mar + apr + may + jun + jul + aug + sep + oct + nov + dec +
wkends + unem + beltlaw + spdlaw, data = traffic2_xts))
summary(lm(totacc ~ t + feb + mar + apr + may + jun + jul + aug + sep + oct + nov + dec +
wkends + unem + beltlaw + spdlaw, data = traffic2_xts))
plot(traffic2_xts$unempo)
plot(traffic2_xts$unemp)
plot(traffic2_xts$unem)
plot(traffic2_xts$totacc)
plot(traffic2_xts$unem)
plot(traffic2_xts$totacc)
plot(traffic2_xts$unem)
plot(traffic2_xts$totacc)
plot(traffic2_xts$unem)
plot(stl(traffic2_xts$prcfat, s.window = "periodic"))
plot(stl(traffic2_xts$prcfat, s.window = "periodic"))
summary(lm(prcfat ~ year + feb + mar + apr + may + jun + jul + aug + sep + oct + nov + dec +
wkends + unem + beltlaw + spdlaw, data = traffic2_xts))
summary(lm(prcfat ~ t + feb + mar + apr + may + jun + jul + aug + sep + oct + nov + dec +
wkends + unem + beltlaw + spdlaw, data = traffic2_xts))
1.766e-01
dat <- read_dta("../data/productivity.dta")
var_label(dat)
View(dat)
dat_ts <- ts(dat, frequency = 12, start = 1972)
prod_xts <- as.xts(dat_ts)
plot(prod_xts$unemployment)
plot(prod_xts$productivity)
plot(dat$productivity, dat$unemployment, cex = 0)
text(dat$productivity, dat$unemployment, label = dat$year)
plot(dat$productivity, dat$unemployment, cex = 0)
text(dat$productivity, dat$unemployment, label = dat$year)
dat_ts <- ts(dat, frequency = 1, start = 1972)
prod_xts <- as.xts(dat_ts)
plot(prod_xts$unemployment)
plot(dat$productivity, dat$unemployment, cex = 0)
text(dat$productivity, dat$unemployment, label = dat$year)
plot(dat$productivity)
plot(dat$productivity, dat$unemployment, cex = 0)
text(dat$productivity, dat$unemployment, label = dat$year)
plot(dat$productivity, dat$unemployment )
text(dat$productivity, dat$unemployment, label = dat$year)
summary(model1 <- lm(unemployment ~ productivity, data = dat))
summary(lm(unemployment ~ year, data = dat))
summary(lm(productivity ~ year, data = dat))
adf.test(dat$unemployment)
adf.test(dat$productivity)
summary(lm(unemployment ~ lag(unemployment, 1), data = dat))
acf(dat$unemployment, na.action = na.pass)
dat$unemployment_d <- c(NA, diff(dat$unemployment))
dat$productivity_d <- c(NA, diff(dat$productivity))
acf(dat$unemployment_d, na.action = na.pass)
acf(dat$productivity_d, na.action = na.pass)
?acf
acf(dat$unemployment_d, na.action = na.pass)
acf(dat$productivity_d, na.action = na.pass)
summary(model_out <- lm(unemployment_d ~ productivity_d, data = dat))
summary(model_out <- lm(unemployment_d ~ lag(productivity_d), data = dat))
names(dat)
summary(model_out <- lm(unemployment_d ~ productivity_d + corp_prft_finance, data = dat))
diff(dat$unemployment)
nrow(dat)
dat$unemployment_d <- diff(dat$unemployment)
source("packages.r")
source("functions.r")
dat <- read_dta("../data/CPDS-1960-2015.dta")
dat <- filter(dat, emu == 1) # only EMU countries
View(dat)
hist(dat$gov_left2)
hist(dat$socexp_t_pmp)
ggplot(data=dat, aes(x=year,y=gov_left2)) +
geom_line(stat="identity") +
ylim(0, 100) +
labs(y = "Left parties in government (% seats in parliament)",
x = "Year") +
geom_line(data = dat, aes(x = year, y = socexp_t_pmp*5), color = "blue") +
scale_y_continuous(sec.axis = sec_axis(~./5, name = "Social expenditures [%GDP]")) +
facet_wrap(~iso, ncol = 6) +
theme(axis.text.x = element_text(angle=90))
names(dat)
dat <- dplyr::select(dat, year, country, iso, eu, emu, gov_left2, socexp_t_pmp, instcons, unemp)
head(dat)
?reshape
class(dat)
dat_wide <- reshape(as.data.frame(dat), direction = "wide", timevar = "year", idvar = c("country", "iso"))
View(dat_wide)
View(dat)
names(dat_wide)
dat_long <- reshape(dat_wide, idvar = c("country", "iso"), varying = 3:104, direction = "long")
View(dat_long)
View(dat)
dat_long <- reshape(dat_wide, idvar = c("country", "iso"), varying = 3:104, direction = "long")
View(dat_long)
data("fertil1")
nrow(fertil1)
summary(lm(kids ~ age + educ + black + age + I(age^2) + east + northcen + west + farm + othrural + town + smcity + y74 + y76 + y78 + y80 + y82 + y84, data = fertil1))
year_dummies <- paste0("y", seq(74, 84, 2))
year_dummies
seq(1, 10, 4)
source("packages.r")
source("functions.r")
data("slp75_81")
?slp75_81
dat <- slp75_81
View(dat)
dat$slpnap_d <- dat$slpnap81 - dat$slpnap75 # differencing the data - super easy in wide format!
plot(dat$slpnap_d, dat$cslpnap) # should be the same
2000/60
2000/60/7
dat$age81 <- dat$age75 + 6
dat_wide <- dplyr::select(dat, male, age75, educ75, gdhlth75, marr75, slpnap75, totwrk75, yngkid75, age81, educ81, gdhlth81, marr81, slpnap81, totwrk81, yngkid81) %>% as.data.frame()
names(dat_wide)
dat_long <- reshape(dat_wide, varying = 2:15, v.names = c("age", "educ", "gdhlth", "marr", "slpnap", "totwrk", "yngkid"), idvar = "id_var", direction = "long")
View/dat_long
View(dat_long)
summary(lm(slpnap ~ totwrk + educ + marr + yngkid + gdhlth, data = dat_long))
.145*60
summary(lm(cslpnap ~ ctotwrk + ceduc + cmarr + cyngkid + cgdhlth, data = dat))
summary(lm(slpnap ~ totwrk + educ + marr + yngkid + gdhlth, data = dat_long))
source("packages.r")
source("functions.r")
dat <- dplyr::select(dat, year, country, iso, gov_left2, socexp_t_pmp, instcons, unemp, eu)
dat <- read_dta("../data/CPDS-1960-2015.dta")
dat <- dplyr::select(dat, year, country, iso, gov_left2, socexp_t_pmp, instcons, unemp, eu)
head(dat)
table(dat$iso)
pdim(dat, index = c("iso", "year"))
dat <- read_dta("../data/CPDS-1960-2015.dta")
dat <- dplyr::select(dat, year, country, iso, gov_left2, socexp_t_pmp, instcons, unemp, eu)
pdim(dat, index = c("iso", "year"))
browseURL("https://cran.r-project.org/web/packages/plm/vignettes/plm.pdf")
summary(model_pooled <- lm(socexp_t_pmp ~ gov_left2 + instcons  + unemp, data = dat))
View(dat)
hist(dat$gov_left2)
summary(model_pooled_plm <- plm(socexp_t_pmp ~ gov_left2 + instcons  + unemp, data = dat, index = c("iso", "year"), model = "pooling"))
summary(model_fe <- lm(socexp_t_pmp ~ gov_left2 + instcons  + unemp + iso, data = dat))
summary(model_fe_plm <- plm(socexp_t_pmp ~ gov_left2 + instcons + unemp, data = dat, index = c("iso", "year"), model = "within"))
pFtest(model_fe_plm, model_pooled_plm) # F test FE vs polling model
coef(model_fe)
fixed_effects <- c(coef(model_fe)[1],
coef(model_fe)[1] + coef(model_fe)[5:(length(coef(model_fe)))])
fe_dat <- data.frame(iso = unique(model_fe$model$iso),
fixed_effect = fixed_effects)
View(fe_dat)
fixef(model_fe_plm)
View(fe_dat)
ggplot(fe_dat, aes(x = reorder(iso, fixed_effect), y = fixed_effect)) + geom_bar(stat = "identity") + labs(x = "")
ggplot(fe_dat, aes(x = reorder(iso, fixed_effect), y = fixed_effect)) + geom_bar(stat = "identity") + labs(x = "")
dat_sum <- group_by(dat, iso) %>% summarize(n_obs = n(),
mean_socexp = mean(socexp_t_pmp, na.rm = T))
fe_dat <- merge(fe_dat, dat_sum, by = "iso", all.x = TRUE)
plot(fe_dat$fixed_effect, fe_dat$mean_socexp)
text(fe_dat$fixed_effect, fe_dat$mean_socexp, fe_dat$iso)
summary(model_fe_time <- plm(socexp_t_pmp ~ gov_left2 + instcons + gov_left2 + unemp + as.factor(year), data = dat, index = c("iso", "year"), model = "within"))
summary(model_re_plm <- plm(socexp_t_pmp ~ gov_left2 + instcons + unemp, data = dat, index = c("iso", "year"), model = "random"))
format(coef(model_fe_plm), scientific = FALSE)
format(coef(model_re_plm), scientific = FALSE)
summary(model_fe_plm)
# load packages
source("../packages.r")
## data import ------------------------------
# waves_df_wide
load("../../data/surveys_ger/yougov_panel_ger_wide.RData")
# waves_df_long
load("../../data/surveys_ger/yougov_panel_ger_long.RData")
source("packages.r")
data("gpa3")
names(gpa3)
length(unique(gpa3$id))
hist(gpa3$trmgpa)
?gpa3
hist(gpa3$sat)
800*.002
200*.002
head(gpa3)
source("packages.r")
source("functions.r")
f <- function(x) x^2
f
f(3)
f(3, 4)
f(c(3, 4))
f <- function(x, y) x^2 + 3*y
f(3, 4)
f(y = 3, x = 4)
mean
my_mean <- function(my_vector) {
mean <- sum(my_vector)/length(my_vector)
mean
}
my_mean(c(1, 2, 3))
my_mean
my_mean <- function(my_vector) sum(my_vector)/length(my_vector)
my_mean(c(1, 2, 3))
remainder <- function(num = 10, divisor = 4) {
remain <- num %% divisor
remain
}
remainder()
remainder(10, 3)
args(remainder)
ultimateAnswer <- function(x) {42}
ultimateAnswer("Is H0 true?")
normalize <- function(x, na.rm = FALSE) {
y <-  (x - mean(x, na.rm = na.rm))/sd(x, na.rm = na.rm)
y
}
vec <- c(1, 5, 10, NA)
normalize(vec, na.rm = TRUE)
normalize(vec, na.rm = TRUE) %>% summary
normalize(vec, na.rm = TRUE) %>% sd(na.rm = TRUE)
normalize(vec, na.rm = FALSE) %>% summary
?Distributions
?rnorm
y <- rnorm(1000, mean = 0, sd = 1)
plot(y)
plot(density(y))
y <- rnorm(10000, mean = 0, sd = 1)
plot(y)
plot(density(y))
dnorm(0, mean = 0, sd = 1)
z_scores <- seq(-3, 3, by = .1)
z_scores
dvalues <- dnorm(z_scores)
dvalues
plot(z_scores, dvalues, type = "l", main = "pdf of the Standard Normal", xlab = "Z score")
pnorm(0)
pnorm(-1)
pnorm(1.96)
pnorm(1.96, lower.tail = FALSE)
?dnorm
?rbinom
p <- 0.5
n <- 100
size <- 5
tmp <- rbinom(n, size, p)
tmp <- rbinom(n, size, p)
table(tmp)
plot(table(tmp), xlab = "Sum of 1 in N", ylab = "Occurrence in n = 100")
text(4.5, c(27, 24, 21), c(paste0("n = ", n), paste0("p = ", p), paste0("N = ", size)))
set.seed(1234)
flips <- rbinom(n = 100, size = 1, prob = .4)
table(flips)
dbinom(1, size = 1, prob = .5, log = TRUE)
dbinom(1, size = 1, prob = .5)
dbinom(0, size = 1, prob = .5)
dbinom(0, size = 1, prob = .4)
dbinom(1, size = 1, prob = .4)
# define likelihood function
binom_loglik <- function(x, p) { # x: vector of results/observed 0s and 1s, p: probability of success
llik <- sum(dbinom(x, size = 1, prob = p, log = TRUE)) # calculate log likelihood with pdf for binomial distribution
return(-llik) # return the negative log likelihood
}
llks <- vector()
probs <- seq(0, 1, .01)
for (i in seq_along(probs)) {
llks[i] <- -sum(dbinom(flips, size = 1, prob = probs[i], log = TRUE))
}
plot(probs, -llks, type = "l")
abline(v = probs[which.min(llks)], col = "red", lty = 2)
?optim
result <- optim(par = .5, fn = binom_loglik, x = flips, method = 'Brent', lower = 0, upper = 1)
result
result <- optim(par = .1, fn = binom_loglik, x = flips, method = 'Brent', lower = 0, upper = 1)
result
# prepare data, run OLS
data("wage1")
wage_ols <- lm(wage ~ educ, data = wage1)
summary(wage_ols)
y <- wage1$wage
X <- cbind(1, wage1$educ)
# 1. Squared residuals
ols <- function(y, X, b) {
res <- y - X %*% b # calculate residuals
return(sum(res^2, na.rm = TRUE))
}
# this function calculates the sum of squared residuals
# OLS is defined to return coefficients that give the smallest possible
# sum of squared residuals
# 2. normally distributed residuals
normal_loglik <- function(theta, y, X) {
b <- theta[-length(theta)] # b's
sigma <- theta[length(theta)] # sigma
res <- y - X %*% b # residuals
return(-sum(dnorm(res, mean = 0, sd = sigma, log = TRUE), na.rm = TRUE))
}
# implies the following assumption on the distribution of e:
# y = f(X, b) + e with e ~ N(0, sigma)
# 3. normally distributed y
normal2_loglik <- function(theta, y, X) {
b <- theta[-length(theta)] # b's
sigma <- theta[length(theta)] # sigma
yhat <- X %*% b # predicted values for y
return(-sum(dnorm(y, mean = yhat, sd = sigma, log = TRUE), na.rm = TRUE))
}
# an equivalent formulation is
# y ~ f(theta, sigma) with theta = g(X, b)
result_normal <- optim(par = c(1, 1, 1), fn = normal_loglik, y = y, X = X, method = "BFGS")
result_normal
summary(wage_ols)
result <- optim(par = c(1, 1, 1), fn = normal_loglik, y = y, X = X, hessian = TRUE) # set hessian = TRUE to optain Hessian matrix, which contains the second-order partial derivates
inv_hess <- solve(result$hessian) # take the inverse of the Hessian to get the Fisher information matrix
sigma <- sqrt(diag(inv_hess)) # the square root of the diagonals are then the standard errors
sigma
estimates_df <- data.frame(params = result$par,
ci95lo = result$par - 1.96 * sigma,
ci95hi = result$par + 1.96 * sigma)
rownames(estimates_df) <- c("beta_0", "beta_1", "sigma2")
estimates_df
?dbern
?dbinom
source("packages.r")
poisson_lik  <- function(mu, x) {
logl <- sum(dpois(x, lambda = mu, log = TRUE), na.rm = TRUE)
return(-logl)
}
# optimize
optim(1, poisson_lik, x = dat_pois, method = "BFGS")
res <- optim(1, poisson_lik, x = dat_pois, method = "BFGS")
dat_pois <- rpois(1000, 3)
mean(dat_pois)
sd(dat_pois)^2
res <- optim(1, poisson_lik, x = dat_pois, method = "BFGS")
res
inv_hess <- solve(res$hessian)
sigma <- sqrt(diag(inv_hess))
res <- optim(1, poisson_lik, x = dat_pois, method = "BFGS", hessian = TRUE)
inv_hess <- solve(res$hessian)
sigma <- sqrt(diag(inv_hess))
sigma
diag(inv_hess)
exp(-0)
exp(-1000)
exp(--10)
source("packages.r")
source("functions.r")
data("turnout") # example dataset from the Zelig package
?turnout
tabyl(turnout$vote)
source("packages.r")
source("functions.r")
tabyl(turnout$vote)
table(turnout$vote)
source("packages.r")
tabyl(turnout$vote)
source("packages.r")
tabyl(turnout$vote)
?glm
logit_out <- glm(vote ~ age + educate + income,
family = binomial, data = turnout)
summary(logit_out)
logit_loglik <- function(theta, y, X){
b <- theta
logl <- sum(-y*log(1+exp(- X %*% b)) # for y = 1
- (1-y)*log(1+exp(X %*% b))) # for y = 0
return(-logl)
}
logit_out_manual <- optim(rep(1,4), logit_loglik, y = turnout$vote, X = as.matrix(cbind(1,(turnout[,c("age", "educate", "income")]))), method = "BFGS")
logit_out_manual
summary(probit_out) # careful - the coefficients are not directly comparable with those from the logit model! (Divide logit coefficients by approximately 1.6 to arrive at probit coefficients; see http://andrewgelman.com/2006/06/06/take_logit_coef/)
probit_out <- glm(vote ~ age + educate + income,
family = binomial(link = "probit"), data = turnout)
summary(probit_out) # careful - the coefficients are not directly comparable with those from the logit model! (Divide logit coefficients by approximately 1.6 to arrive at probit coefficients; see http://andrewgelman.com/2006/06/06/take_logit_coef/)
# again, a little simulation
n <- 100
x <- rnorm (n)
a <- 1.5
b <- 1
y <- rbinom (n, 1, invlogit(a + b*x))
M1 <- glm (y ~ x, family=binomial(link="logit"))
summary (M1)
M2 <- glm(y ~ x, family=binomial(link="probit"))
summary (M2)
logit_out_empty <- glm(vote ~ 1, family = binomial, data = turnout) # estimate empty model
summary(logit_out_empty)
Pseudo_R2 <- 1 - (as.numeric(logLik(logit_out)))/(as.numeric(logLik(logit_out_empty)))
Pseudo_R2
turnout$vote_pred_link <- predict(logit_out, type = "link")
turnout$vote_pred_link#
turnout$vote_pred_prob <- predict(logit_out, type = "response")
turnout$vote_pred_prob
hist(turnout$vote_pred_prob)
turnout$vote_pred <- ifelse(turnout$vote_pred_prob > .5, 1, 0)
plot(turnout$vote_pred_link, turnout$vote_pred_prob) # links versus response
tab <- table(turnout$vote, turnout$vote_pred)
colnames(tab) <- c("pred vote NO", "pred vote YES")
rownames(tab) <- c("rep vote NO", "rep vote YES")
tab
sum(turnout$vote_pred == 1 & turnout$vote == 1) / sum(turnout$vote_pred == 1)
sum(turnout$vote_pred == 1 & turnout$vote == 1) / sum(turnout$vote == 1)
summary(logit_out)
cbind(log_odds <- round(coef(logit_out), 4),
odds_ratios <- round(exp(coef(logit_out)), 4),
probabilities <- round(1/(1+exp(-coef(logit_out))), 4))
library(margins)
summary(logit_out)
margins(logit_out, type = "link") # this equals the log odds
margins(logit_out, type = "response") # this equals marginal probabilities
margins(logit_out, at = list(age = c(25, 60),
educate = c(10, 10),
income = c(3, 3)))
marginal_effects(logit_out) # unit-specific marginal effects with respect to all variables
df <- data.frame(age = min(turnout$age):max(turnout$age), educate = 10, income = 4)
model_preds <- predict(logit_out, newdata = df, type = 'response', se.fit = TRUE)
df$prediction <- model_preds$fit
df$lower <- model_preds$fit - 1.96 * model_preds$se.fit
df$upper <- model_preds$fit + 1.96 * model_preds$se.fit
ggplot(df) + geom_line(aes(x = age, y = prediction)) + theme_bw() + geom_ribbon(aes(ymin = lower, ymax = upper, x = age), alpha = .3)
cplot(logit_out, "age")
cplot(logit_out, "age", what = "effect")
3200+2800
